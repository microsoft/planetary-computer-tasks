#!/bin/bash

function require_env() {
    v=$(eval echo \$${1})

    if [[ -z ${v} ]]; then
        echo "${1} must be set as environment variable" >&2
        echo "Check deployment/docker-compose.yml for host environment requirements" >&2
        exit 1
    fi
}

function setup_env() {

    # Directory for rendered values and templates
    export CONF_DIR="${CONF_DIR:-/opt/conf}"
    export SRC_DIR="${SRC_DIR:-/opt/src}"
    mkdir -p ${CONF_DIR}

    # Paths for genrating deployment values
    export TEMPLATE_PATH=helm/deploy-values.template.yaml
    export TF_OUTPUT_FILE=$(realpath ${CONF_DIR}/tf-output.json)
    export DEPLOY_VALUES_FILE=$(realpath ${CONF_DIR}/deploy-values.yaml)

    export DATE=$(date)
}

function tf_output() {
    echo $(terraform output -json resources | jq -r .${1})
}

function gather_tf_output() {

    if [ "${1}" ]; then
        pushd ${1} || return;
    fi

    echo "Gathering terraform output..."

    # Export output values
    terraform output -json > ${TF_OUTPUT_FILE}

    # Record terraform output variables for cluster login
    export RESOURCE_GROUP=$(tf_output resource_group)
    export CLUSTER_NAME=$(tf_output cluster_name)

    export ENVIRONMENT=$(tf_output environment)
    export INGRESS_IP=$(tf_output ingress_ip)
    export DNS_LABEL=$(tf_output dns_label)
    export INTERNAL_INGRESS_IP=$(tf_output internal_ingress_ip)
    export AZURE_TENANT=$(tf_output tenant_id)
    export KEYVAULT_NAME=$(tf_output secret_provider_keyvault_name)
    export SECRET_PROVIDER_MANAGED_IDENTITY_ID=$(tf_output secret_provider_managed_identity_id)
    export SECRET_PROVIDER_KEYVAULT_SECRET=$(tf_output secret_provider_keyvault_secret)

    if [ "${1}" ]; then
        popd
    fi
}

function render_values() {
    echo "Rendering chart value files..."

    bin/jinja ${TF_OUTPUT_FILE} ${TEMPLATE_PATH} ${DEPLOY_VALUES_FILE}
}

function cluster_login() {
    echo "Logging into the cluster..."

    if [ -z "${RESOURCE_GROUP}" ]; then
        RESOURCE_GROUP=$1
    fi

    if [ -z "${CLUSTER_NAME}" ]; then
        CLUSTER_NAME=$2
    fi

    az aks get-credentials \
        --resource-group ${RESOURCE_GROUP} \
        --name ${CLUSTER_NAME} \
        --subscription ${ARM_SUBSCRIPTION_ID} \
        --overwrite-existing \
        --file=kubeconfig

    # kubelogin mutates every entry in the kubeconfig
    # https://github.com/Azure/kubelogin/issues/87.
    # So we export to a kubeconfig file
    echo "Converting kubeconfig..."
    kubelogin convert-kubeconfig \
        -l azurecli \
        --kubeconfig=kubeconfig
        # --client-id ${ARM_CLIENT_ID} \
        # --client-secret ${ARM_CLIENT_SECRET} \
    export KUBECONFIG=kubeconfig
}

function setup_helm() {
    # Set the helm context to the same as the kubectl context
    export KUBE_CONTEXT=$(kubectl config current-context)
}

function full_setup() {
    if [[ -z ${1} ]]; then
        echo "Must pass in terraform directory."
    else
        echo "Using terraform at ${1}..."
        setup_env;
        gather_tf_output ${1};
        render_values;
        cluster_login;
        setup_helm;
    fi
}

function get_argo_token() {
    echo "Bearer $(kubectl get secret -n pc pctasks-sa-token -o jsonpath='{.data.token}' | base64 --decode)"
}

function set_tf_vars() {
    KEYVAULT_NAME=$1
    KEYVAULT_SECRET_NAME=$2
    TV_VARS_FILE=$3
    if [ -f ${TV_VARS_FILE} ]; then
        az keyvault secret set --vault-name "${KEYVAULT_NAME}" --name "${KEYVAULT_SECRET_NAME}" --file "${TV_VARS_FILE}"
    else
        echo "File ${TV_VARS_FILE} not found."
    fi
}


function prepare_funcs() {
    rm -rf "${SRC_DIR}/functions_deploy"
    cp -r "${SRC_DIR}/pctasks_funcs" "${SRC_DIR}/functions_deploy"

    pushd "${SRC_DIR}/functions_deploy" || exit
    # Create symlink to enable function app building of pctasks
    ln -s "${SRC_DIR}/pctasks" "${SRC_DIR}/functions_deploy/pctasks_linked"
    cp requirements-deploy.txt requirements.txt

    popd || exit
}

function get_cidr_range() {
    runnerIpAddress=$(curl -s https://ifconfig.me/all.json | jq -r ".ip_addr")
    IFS='.' read -r -a ip_parts <<< "$runnerIpAddress"
    echo "${ip_parts[0]}.${ip_parts[1]}.0.0/16"
}

function disable_shared_access_keys() {
    echo "Disabling shared access key on storage account..."

    echo "${SAK_STORAGE_ACCOUNTS[@]}"

    for SAK_STORAGE_ACCOUNT in "${!SAK_STORAGE_ACCOUNTS[@]}"; do
        SAK_RESOURCE_GROUP=${SAK_STORAGE_ACCOUNTS[$SAK_STORAGE_ACCOUNT]}

        echo "   - disabling ${SAK_STORAGE_ACCOUNT} / ${SAK_RESOURCE_GROUP}"
        az storage account update \
            --name ${SAK_STORAGE_ACCOUNT} \
            --resource-group ${SAK_RESOURCE_GROUP} \
            --allow-shared-key-access false \
            --subscription ${ARM_SUBSCRIPTION_ID} \
            --output none

        if [ $? -ne 0 ]; then
            echo "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
            echo "WARNING: Failed to turn off shared key access on the storage account."
            echo "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
            exit 2
        fi
    done
}

function enable_shared_access_keys() {
    echo "Enabling shared key access for storage account..."
    # Terraform isn't able to read all resources from a storage account if shared key access is disabled
    # so while we're deploying, we need to enable it. Since we haven't run TF yet, we don't have the name of the account
    # so they are hardcoded here. This is a temporary workaround until this is resolved
    # https://github.com/hashicorp/terraform-provider-azurerm/issues/25218

    for SAK_STORAGE_ACCOUNT in "${!SAK_STORAGE_ACCOUNTS[@]}"; do
        SAK_RESOURCE_GROUP=${SAK_STORAGE_ACCOUNTS[$SAK_STORAGE_ACCOUNT]}

        echo "   - enabling ${SAK_STORAGE_ACCOUNT} / ${SAK_RESOURCE_GROUP}"
        az storage account update \
            --name ${SAK_STORAGE_ACCOUNT} \
            --resource-group ${SAK_RESOURCE_GROUP} \
            --allow-shared-key-access true \
            --subscription ${ARM_SUBSCRIPTION_ID} \
            --output none
    done

    sleep 10
}

function add_ip_to_storage_firewalls() {
    cidr=$(get_cidr_range)

    # Also add the IP to the terraform state storage account
    for FW_STORAGE_ACCOUNT in "${!FW_STORAGE_ACCOUNTS[@]}"; do
        FW_RESOURCE_GROUP=${FW_STORAGE_ACCOUNTS[$FW_STORAGE_ACCOUNT]}
        echo "Adding IP $cidr to ${FW_STORAGE_ACCOUNT} Storage firewall allow list..."
        az storage account network-rule add \
            -g ${FW_RESOURCE_GROUP} \
            -n ${FW_STORAGE_ACCOUNT} \
            --ip-address $cidr \
            --subscription ${ARM_SUBSCRIPTION_ID} \
            --output none
    done
    
}

function remove_ip_from_storage_firewalls() {
    cidr=$(get_cidr_range)

    for FW_STORAGE_ACCOUNT in "${!FW_STORAGE_ACCOUNTS[@]}"; do
        FW_RESOURCE_GROUP=${FW_STORAGE_ACCOUNTS[$FW_STORAGE_ACCOUNT]}
        echo "Removing IP $cidr from ${FW_STORAGE_ACCOUNT} Storage firewall allow list..."
        az storage account network-rule remove \
            -g ${FW_RESOURCE_GROUP} \
            -n ${FW_STORAGE_ACCOUNT} \
            --ip-address $cidr \
            --subscription ${ARM_SUBSCRIPTION_ID} \
            --output none
    done
}
